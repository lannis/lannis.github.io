<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Lovelife</title><link href="http://lannis.github.io/" rel="alternate"></link><link href="http://lannis.github.io/feeds/all.atom.xml" rel="self"></link><id>http://lannis.github.io/</id><updated>2015-11-04T00:03:00+08:00</updated><entry><title>GreenPlum中高可用实现与恢复简介</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-02/" rel="alternate"></link><updated>2015-11-04T00:03:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-11-04:articles/greeplum-code-analysis-02/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;在上一篇&lt;/em&gt;&lt;/strong&gt;文章中介绍了除了master外，primary和mirror的进程以及其主要的作用。本文主要从业务流程上将各个进程的处理功能串联一下。 &lt;/p&gt;
&lt;h4&gt;GreenPlum中的文件&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;在PostgreSQL数据库&lt;/em&gt;&lt;/strong&gt;中主要存在两类文件：数据文件和非数据文件。这两个概念在GreenPlum中用BufferPoolFile和FlatFile来说明。相对于PostgreSQL，在GreenPlum增加了另外一种文件类别--append only，什么意思呢？查了一下相关的概念:  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This allows for more compact storage on disk because each row does not need to store the MVCC(Unlike traditional database systems which use locks for concurrency control, Greenplum Database (as does PostgreSQL) maintains data consistency by using a multiversion model (multiversion concurrency control or MVCC). This means that while querying a database, each transaction sees a snapshot of data which protects the transaction from viewing inconsistent data that could be caused by (other) concurrent updates on the same data rows. This provides transaction isolation for each database session.MVCC, by eschewing explicit locking methodologies of traditional database systems, minimizes lock contention in order to allow for reasonable performance in multiuser environments. The main advantage to using the MVCC model of concurrency control rather than locking is that in MVCC locks acquired for querying (reading) data do not conflict with locks acquired for writing data, and so reading never blocks writing and writing never blocks reading.) transaction visibility info. This saves 20 bytes per row. AO tables can also be compressed.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;根据前面&lt;/em&gt;&lt;/strong&gt;介绍的primary和mirror多进程差异，需要思考的一个问题是，数据如何在其之间&lt;em&gt;同步&lt;/em&gt;的？在GreenPlum中定义了一类文件同步操作接口，在primary上主要为FileRepPrimary_mirror&lt;em&gt;，在mirror上主要为FileRepMirror_&lt;/em&gt;。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;前面提到&lt;/em&gt;&lt;/strong&gt;在GreenPlum中总共有三类文件类型，拿primary为例，其在FileRepPrimary_mirror*之上封装了三类操作，分别为：&lt;br /&gt;
&lt;code&gt;cdb/cdbmirroredappendonly.c: MirroredAppendOnly_Open();MirroredAppendOnly_Create();...  
cdb/cdbmirroredbufferpool.c: MirroredBufferPool_Open();MirroredBufferPool_Create();...   
cdb/cdbmirroredflatfile.c: MirroredFlatFile_Open();MirroredFlatFile_Create();...&lt;/code&gt;&lt;br /&gt;
实际上在cdb目录下还存在另外一种mirror操作：cdbmirroredfilesysobj.c中定义的接口，实际上这些操作并没有直接参与primary-mirror同步，此处不详细展开。  &lt;/p&gt;
&lt;h4&gt;GreenPlum中的高可用&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;那么&lt;/em&gt;&lt;/strong&gt;介绍了这些接口的概念后，业务数据如何在primary和mirror间同步的呢？举一个很简单的列子：针对一个simple table，执行语句INSERT INTO table VALUES (...)往表中插入记录。语句经过词法-&amp;gt;语法-&amp;gt;语义-&amp;gt;计划-&amp;gt;优化-&amp;gt;执行，可能简单语句会跳过很多处理，最终会调用heap_insert将记录插入到heap page中，并且针对这个插入操作封装一条xlog record插入到wal page中。数据最终被转化为格式化的信息存到了两类文件中，&lt;em&gt;数据文件&lt;/em&gt;以及&lt;em&gt;日志文件&lt;/em&gt;。在GreenPlum中这两种存储的信息会从primary同步到mirror。   &lt;/p&gt;
&lt;p&gt;回忆一下，在PostgreSQL中的高可用是这样的：主机(primary)上执行insert同样会产生数据和日志信息并写入存储介质，存在一个进程walsender进程，周期性检测日志文件是否被更新，看清楚是日志文件 日志文件 日志文件，如果发现日志文件发生更新，则&lt;strong&gt;从日志文件中&lt;/strong&gt;读取新插入的那些日志记录，通过网络发送到备机(mirror)，备机alreceiver进程收到日志记录后写入到相应的日志文件中，由恢复进程startup读取文件中新写入的日志记录进行恢复，从而完成主备的一个同步过程。由于涉及到跨网络的进程传输，因此在walsender-walreceiver之间增加了心跳信息。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;GreenPlum&lt;/em&gt;&lt;/strong&gt;与PostgreSQL不同之处在于，日志和数据都会同步到备机，而不单单是日志，并且同步的方式不同，信息的同步直接是从内存同步而没有经过写盘读取磁盘上的数据这样的过程，效率相对要高一些。  &lt;/p&gt;
&lt;h5&gt;日志同步&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;产生日志时&lt;/em&gt;&lt;/strong&gt;，backend进程会调用XLogWrite函数将日志信息写入磁盘，并且根据条件决定是否需要flush。在GreenPlum中，日志的打开读写都与主备同步点滴相关。写记录来举例一下，在PostgreSQL中使用write函数将日志写入磁盘就完了，在GreenPlum中要复杂的多，具体而言，因为日志文件是flat file，因此此处使用MirroredFlatFile_Write函数替换了write函数。    &lt;/p&gt;
&lt;p&gt;MirroredFlatFile_Write函数中，首先调用前面介绍的更底层的操作接口FileRepPrimary_MirrorWrite将数据发送给备机，然后使用FileSeek&amp;amp;FileWrite接口将数据才真正的写入本地日志文件。    &lt;/p&gt;
&lt;p&gt;展开来看FileRepPrimary_MirrorWrite函数中，首先通过FileRep_ReserveShmem()从共享内存申请空间，然后针对要同步的数据，构造FileRepMessageHeader，将消息头以及需要同步的数据放入申请的共享空间。使用FileRep_IpcSignal通知消费者去共享内存中取数据。这个就是所谓前面提到的通过信号量及共享内存进行程序内多进程的同步。  &lt;/p&gt;
&lt;p&gt;这里的消费者就是primary sender进程，进程的工作方式以及作用参见前文中的介绍，sender进程将数据再封装发送到备机端， 备机的mirror receiver进程将受到的数据进行初步解析确定属于哪种类型的数据，将数据同样放入本地的接受共享空间，针对不同的数据类型使用ipc信号通知不同的消费者，这里就是为什么备机上会有三个消费者(mirror consumer、mirror consumer writer以及mirror consumer append only)的原因了。  &lt;/p&gt;
&lt;p&gt;当前场景下日志数据属于flat file，此处通知的是mirror comsumer进程，mirror comsumer进程从共享内存中取到最新的日志数据，发现类型为FileRepOperationWrite，将日志写入对应的日志文件。本次日志信息同步结束。  &lt;/p&gt;
&lt;h5&gt;数据同步&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;数据同步&lt;/em&gt;&lt;/strong&gt; 不同于日志同步，日志同步在日志记录产生时就会同步，而数据并非如此，INSERT修改或者产生页面后，页面被缓存在bufferpool中，当发生checkpoint时，会调用flushbuffer将所有脏页面刷盘，最终调用存储底层smgrwrite的实现mdwrite将数据页面写入磁盘。  &lt;/p&gt;
&lt;p&gt;在GreenPlum中数据的同步就发生在这个阶段，mdwrite真正的实现被封装为MirroredBufferPool_Write，就是我们上面提到的其中一类接口中的一种。MirroredBufferPool_Write底层调用FileRepPrimary_MirrorWrite将页面数据同步到备机，整体流程与日志类似，此处不再详述。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;实际上&lt;/em&gt;&lt;/strong&gt;在GreenPlum中的主备同步，存在同步和异步的区别，即有些操作主机不需要等待数据同步到备机，比如前面提到的两类。同样存在其他操作需要强同步的，在GreenPlum中的实现方式一般为：主机先将操作信息放入发送共享队列，同时插入到共享哈希表中，然后进行本地操作，最后等待检查哈希表中备机反馈的信息完成后，操作才算完成。  &lt;/p&gt;
&lt;h5&gt;GreenPlum中的恢复&lt;/h5&gt;
&lt;p&gt;在GreenPlum中只有产生实际数据的实例才需要恢复，和PostgreSQL不同的是，因为数据是直接被同步到备机的，所以备机不需要恢复，在主机发生故障，备机failover时其效率肯定是很不错的。  对于primary和master而言，数据库的恢复与PostgreSQL基本类似，不同之处是在reaper中如果是startup进程退出，则根据条件会拉起另外几个恢复进程进行额外的处理。&lt;/p&gt;
&lt;p&gt;morning sweety.&lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>GreenPlum进程结构简介</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-01/" rel="alternate"></link><updated>2015-10-31T22:45:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-10-31:articles/greeplum-code-analysis-01/</id><summary type="html">&lt;p&gt;前一段时间&lt;a href="https://github.com/greenplum-db/gpdb"&gt;GreenPlum&lt;/a&gt;数据库正式开源了，对于整个行业来说冲击比较大。李元佳(华为/PostgresSQL)写了两篇文章分享分析为什么GreenPlum要开源，以及其开源的影响。 &lt;br /&gt;
我相信很多数据厂商在第一时间拿到了相关的已经开发的技术文档以及在github上托管的代码进行分析，作为一个数据库内核开发人员而言，可能不会直接面对其对市场的冲击带来的压力，但是学习并研究其相关的代码，能够接地气的深入了解到前沿的技术，对自己也是一个很大的提升。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;GreenPlum&lt;/em&gt;&lt;/strong&gt;相关的开源协议以及其各种高大上的介绍，这里就不重复再重复了，网上太多了。提一点, GreenPlum是基于PostgreSQL 8.2.13内版本做的开发，当然可能最初的版本不是这个，通过一系列开源特性回合回合到这个版本。通过copyrights可以看到，从06年到现在，GreenPlum已经做了10年了，时间可以证明一切，在此表示敬意。  &lt;/p&gt;
&lt;p&gt;鉴于自己的工作性质，我可能从以下几个方面学习并分享其技术: 进程管理、高可用、备份、恢复以及存储管理等。随着自己学习的加深也可能会多少涉及到其他部分。  &lt;/p&gt;
&lt;p&gt;相对PostgreSQL而言，GreenPlum的进程管理要复杂的多，我们知道在PostgreSQL中通过针对pmState采用状态机进行自我管理。通过阅读GreenPlum的代码我们会发现，其在更high level上增加了一个叫pmModuleState的结构用以管理HA的transition/replication等，复杂度要高的多。  &lt;/p&gt;
&lt;p&gt;在GreenPlum中primary主要包含以下几个进程(ckp/bgw等暂不考虑):&lt;br /&gt;
&lt;em&gt; 1 postmaster process                      &lt;/em&gt;和PostgreSQL功能基本类似，不再详述&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 2 primary process                         &lt;em&gt;负责拉起所有primary相关的进程并负责相关的日志刷新(FileRep_Main)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 3 primary receiver ack process                &lt;/em&gt;接受listensocket0上的连接，连接建立后处理mirror发送的的ack消息,将消息插入shmem(FileRepAckPrimary_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 4 primary sender process                  &lt;em&gt;发起连接连mirror，监控fileRepShmemArray上的信息，重组业务消息发送给mirror(FileRepPrimary_RunSender)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 5 primary consumer ack process                &lt;/em&gt;处理receiver ack收到的消息, 更新到fileRepAckHashShmem-&amp;gt;hash哈希表中(FileRepAckPrimary_RunConsumer)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 6 primary recovery progress               &lt;em&gt;根绝各种消息类型，定期插入不同的hearbeat消息到哈希表，并检查最终从mirror返回更新到哈希表的状态(FileRepPrimary_RunHeartBeat)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 7 primary verification progress           &lt;/em&gt;verify进程，根据请求进行verify(FileRepPrimary_StartVerification)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 8 sweeper progress                            &lt;em&gt;没有细看，字面意思类似于PostgreSQL中的vacuum,只不过监控的是每个backend的CPU状态(BackoffSweeper)&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;mirror主要包含以下几个进程：&lt;br /&gt;
&lt;em&gt; 1 postmaster process                      &lt;/em&gt;和PostgreSQL功能基本类似，不再详述&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 2 mirror progress                         &lt;em&gt;负责拉起所有mirror相关的进程并负责相关的日志刷新(FileRep_Main)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 3 mirror receiver progress                    &lt;/em&gt;接受listenSocket0上的连接，连接建立后处理primary发送的业务消息，通过内部的状态转换决定当前处理方式环节，如先获取消息类型，reserve消息空间，接受数据，通知消费者等(FileRepMirror_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 4 mirror consumer progress                    &lt;em&gt;consumer，类型为FileRepMessageTypeXLog，处理消息中的具体文件操作信息，如打开、写数据、刷盘、关闭，truncate等(FileRepMirror_RunConsumer)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 5 mirror consumer writer progress         &lt;/em&gt;consumer，类型为FileRepMessageTypeWriter，同上&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 6 mirror consumer append only progress        &lt;em&gt;consumer，类型为FileRepMessageTypeAO01，同上&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 8 mirror sender ack progress              &lt;/em&gt;发起连接连primary，监控fileRepAckShmemArray上的信息, 发送ack消息给primary(FileRepAckMirror_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 9 mirror verification progress                &lt;em&gt;consumer，类型为FileRepMessageTypeVerify，同上&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;限于GreeenPlum代码的复杂程度，当前理解有限。先到这里了，后面会加入业务操作，从WAL/数据角度看HA以及进程在GreenPlum中是如何运作的， 如果你对PostgreSQL了解的话，此时应该可以有点眉目了，就是GreenPlum中的primary/mirror同步不单单是WAL。&lt;br /&gt;
一般而言看这种复杂的数据库，可以从多个角度，我一般喜欢从常驻进程/线程分析，看看什么条件会收到请求，这些请求被如何处理了，这些请求的来源又是什么等等。&lt;br /&gt;
补充一点，程序内部多进程采用的是ipc和shmem同步到消息，程序间走的是基于tcp的libpq。  &lt;/p&gt;
&lt;p&gt;时间已经凌晨一点多了，晚安  &lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>rewind in PostgreSQL</title><link href="http://lannis.github.io/articles/rewind/" rel="alternate"></link><updated>2015-10-30T21:30:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-10-30:articles/rewind/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;一个月&lt;/em&gt;&lt;/strong&gt;没有写文章了，这一个月确实比较忙。十一西安到北京，转至青岛，回家，返回西安。回来后又要驾照考试。  &lt;/p&gt;
&lt;p&gt;回到正文上次写到本文准备介绍一下时间线的问题，基于当前的形式，暂且放一下，今天我来介绍PostgreSQL中一个工具rewind。rewind是一个增量备份工具，最早由vmware开发，后来推送到社区后被接纳，我们得以学习到，其实在去年，基于工作性质，我们就做过类似rewind的demo，只是限于时间没有好好细化，搁置了半年之久，后来发现rewind社区已经做了，我花了半天的时间读了一下相关的代码，结构和思想还是比较清晰的。  &lt;/p&gt;
&lt;p&gt;PostgreSQL中传统的全量备份是基于文件系统的拷贝，为了保证在线备份及恢复的一致性，PostgreSQL增加了备份模式，这里不在详细介绍。后来有一个类似的外部工具出现了--rman，日本写的。rman支持全量和增量，全量为文件拷贝，增量是基于全量的基础上，通过当前全量备份的LSN与当前数据页面的LSN作比较，在数据量大时效率仍然不是很好。  &lt;/p&gt;
&lt;p&gt;与rman不同的是rewind采用了一种全新的视角来修复primary/standby关系，rewind通过解析备机上的WAL日志文件逆向获取那些需要还原的数据信息从主机上讲需要还原的信息重新同步到备机。原因是通过日志我们可以获知在备机上发生了什么，参见前文。有两个前提：  备机上从某一时刻和主机分道扬镳，这一个时刻的日志我们可以获取到，并且后续的日志都存在；fullpagewrite。第一个前提比较好理解，第二个前提具体在下文介绍。  &lt;/p&gt;
&lt;p&gt;rewind工具没有采用传统的备机视角，而是采用的普通的客户端视角，通过一系列SQL查询获取其需要的信息。主要过程有以下几部分：&lt;br /&gt;
1.必要的参数检查。&lt;br /&gt;
2.连接主机，对比主备机上control文件，确定两者同源及一些条件的检查。&lt;br /&gt;
3.根据时间线历史文件获取主备分开的日志LSN。&lt;br /&gt;
4.检查当前的备机是否可以不需要做rewind。&lt;br /&gt;
5.前向扫描日志，找到主备一致点前的checkpoint，以这个checkpoint为基准向后解析日志。&lt;br /&gt;
6.初始化filemap结构，后续用来存储需要同步的文件及页面信息。&lt;br /&gt;
7.通过SQL查询的方式获取主机上所有的文件信息，并于本地文件比较，有几种情况，主机上有备机上没有(COPY)，主机比备机大(COPYTAIL)，备机比主机大(TRUNCATE)等等。&lt;br /&gt;
8.读取备机上的文件，检查哪些文件不在主机的文件列表中，需要插入到filemap中标记为要删除(REMOVE)。&lt;br /&gt;
9.从前面找的checkpoint开始解析日志，获取日志中的bkpb中的rel block信息，讲此信息以bit map的方式插入到filemap结构中。&lt;br /&gt;
10.对最终生成的filemap做排序。&lt;br /&gt;
11.遍历filemap，分类处理每一种类型，对于需要向主机同步的，采用SQL的方式，创建临时表，将所有需要向主机同步的文件/块信息以记录的方式放到表中。执行特定的语句，主机遍历临时表中的记录，读取相应的文件/块，发送到备机。&lt;br /&gt;
12.创建backuplabel文件以及调整control文件。&lt;br /&gt;
13.手动以备机方式拉起。  &lt;/p&gt;
&lt;p&gt;整体而言rewind的思想很不错，数据量大时不需要去遍历所有的数据文件，但是限制也颇多，比如，需要完全保留日志，对主备机的停止模式有严格的要求，必须打开fullpagewrite，等等。尽管如此，仍然不失为一个高效率的主备修复工具。当然在很多方面可以做优化，使得工具的适用范围更加广。&lt;/p&gt;</summary><category term="rewind"></category><category term="rman"></category><category term="PostgreSQL"></category></entry><entry><title>timeline in PostgreSQL</title><link href="http://lannis.github.io/articles/learning/" rel="alternate"></link><updated>2015-09-17T22:20:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-17:articles/learning/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;PostgreSQL&lt;/em&gt;&lt;/strong&gt;数据库是一个开源的传统关系性数据库，目前在国内的应用是越来越广泛的。为什么？有些觉得这个数据库功能比较强大，社区比较活跃，然后使用PostgreSQL为基线可以开发针对自己需求场景的数据库，而不必去承担一些责任。  &lt;/p&gt;
&lt;p&gt;但是在我看来，这些都是一些外在的，真正好的还是数据库本身。从2013年起，每次的commit记录我都会看一下学习一下，当然啦，很多patch是看不懂，个人水平有限... PostgreSQL社区的committer真的是一群大牛们，他们对于技术的热爱以及对于CODE本身的严谨程度让我感到震撼，Tom Lane(社区的大哥大，从199×年开始就在运营社区)对每一次提交都有很详细的记录以及很清晰的comments，甚至因为几个white blank或者因为几个注释的单词拼写错误就会去提交一次，让人从内心深处敬佩。所以学习他们的code，就像在欣赏一件艺术品。有他们这些人，PostgreSQL的前景是美好的。  &lt;/p&gt;
&lt;p&gt;因工作需要从2012年下半年就开始接触PostgreSQL相关的事情，印象比较深刻的是关于时间线(timeline)的概念，当时真的是完全不理解，也许吧看过科幻电影、小说。这个是一个很有意思的话题，一个人回到过去杀掉了自己的祖母，然后这个人会发生什么悖论。  &lt;/p&gt;
&lt;p&gt;在数据库中时间线是一个看得见摸得着的东西，因为基于可靠性，数据库会记录日志，一般的日志都是时间+内容的方式，就像日记一样，某一天发生了什么事情。这样一天一天的累积，我们可能写了好多本日记，有这个月的，有去年的，有前年的...   &lt;/p&gt;
&lt;p&gt;举个例子，现在拿起手中的日记本，比如2012年的日记，翻开某一页，其中日记上这么写着，今天想去北京玩，结果因为某些事情没有去成，导致现在没有认识某些人或者没有做某些事。然后我可能会想如果当时下定决心会怎么样... 也会有一个不一样的人生吧。扯远了，数据库中时间线的存在就像一连串起来的日记，我可以选择一天回到过去，做出另外一种选择，描绘另外一种人生。比如之前的时间线是1，那么回到过去做出一些不一样选择后的时间线叫2，以此类推。  &lt;/p&gt;
&lt;p&gt;在PostgreSQL中日志是以WAL记录的方式存储，每一个WAL日志段文件像是一个日记本，我们写完一个，会买另外一个继续写。同样的道理，日志段文件中记录的record就是我们那一天一天的日记。数据库的恢复机制，允许我们从一个过去的时间点开始恢复，恢复到一定时间后后面的日志可以选择性不恢复，从而以全新的状态运行。  &lt;/p&gt;
&lt;p&gt;今天就到这里了，下次主要想总结的是PostgreSQL中replication跨时间线传输在当前版本中的限制。  &lt;/p&gt;
&lt;p&gt;马上中秋节了，中秋节要去北京一趟，去见一些想见的人，然后在北京上三天班，接着去青岛，然后回家。祝中秋快乐。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;MISS U&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</summary><category term="timeline"></category><category term="PostgreSQL"></category></entry><entry><title>70周年</title><link href="http://lannis.github.io/articles/%E6%83%B3%E4%BD%A0/" rel="alternate"></link><updated>2015-09-04T00:32:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-04:articles/想你/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;九月三号&lt;/em&gt;&lt;/strong&gt;阅兵，昨天上午从开始看到结束&lt;br /&gt;
好些年没有这么认真了的看阅兵了，好像感觉也好久没有阅兵了哈哈&lt;/p&gt;
&lt;p&gt;西安下午下着雨,好像明天也会下雨...&lt;br /&gt;
&lt;img alt="想你" src="http://img4.duitang.com/uploads/item/201205/17/20120517133805_FZPsv.jpeg" /&gt;&lt;/p&gt;</summary><category term="抗战"></category><category term="评论"></category></entry><entry><title>About Me</title><link href="http://lannis.github.io/articles/About%20Me/" rel="alternate"></link><updated>2015-09-01T07:49:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-01:articles/About Me/</id><summary type="html">&lt;p&gt;Hello Pelican, Markdown and Github Blogs.&lt;/p&gt;
&lt;h4&gt;感想&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;今天&lt;/em&gt;&lt;/strong&gt;是第一次成功配置github blog，很开心，因为刚开始不是特别的顺利。&lt;br /&gt;
甚至安装Ubuntu Kylin后一段时间Windows 10都启动不起来了。万幸通过boot repair修复了。&lt;br /&gt;
后续相关的学习及心得会在此blog上更新，欢迎访问和评论，哈哈哈&lt;/p&gt;
&lt;h4&gt;链接&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;下面&lt;/em&gt;&lt;/strong&gt;是配置的几个学习的链接，以供收藏和学习:&lt;br /&gt;
&lt;a href="http://www.jianshu.com/p/1e402922ee32/"&gt;Markdown--入门指南&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.linuxzen.com/shi-yong-pelicanda-zao-jing-tai-bo-ke.html"&gt;使用Pelican打造静态博客&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://heylinux.com/archives/3337.html?utm_source=tuicool"&gt;使用Pelican + Markdown + GitHub Pages来撰写Blog&lt;/a&gt;&lt;/p&gt;</summary><category term="Pelican"></category><category term="Markdown"></category></entry></feed>