<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Lovelife</title><link href="http://lannis.github.io/" rel="alternate"></link><link href="http://lannis.github.io/feeds/all.atom.xml" rel="self"></link><id>http://lannis.github.io/</id><updated>2015-12-31T23:47:00+08:00</updated><entry><title>天青色等烟雨</title><link href="http://lannis.github.io/articles/essay-01-of-2016/" rel="alternate"></link><updated>2015-12-31T23:47:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-12-31:articles/essay-01-of-2016/</id><summary type="html">&lt;p&gt;今天心情多少有点复杂，突然觉得在西安呆了好多年了，上大学、工作，弹指间，八个手指快弹出来了，但是就是这么多年过去了，我却似乎始终没有找到归属感，每次从家里归来的火车上心情都特别差，看到别的小伙伴却很开心很开心的回学校啊，回去上班啊，我就在想你们是怎么办到的。  &lt;/p&gt;
&lt;p&gt;现在看来这座城市对我来说，除了一个很好的工作，其他什么都没有。在这边的同学朋友成家的成家，离开的离开，渐渐的我发现，我已经找不到一个人陪我去看电影，陪我玩游戏，陪我买东西了。  &lt;/p&gt;
&lt;p&gt;有人会觉得既然有稳定的工作，应该多多少少会有点归属感吧，有朋友有房子就会好吧。有人曾告诉我有人的地方就有家，彼此呆过的地方都是家，我觉得这个是对的，或许自己牵挂的人不在这里。房子和家是两码事，你的心在哪，你的家就在哪，否则你在不属于你的地方，会有种一言难尽的感觉。 &lt;/p&gt;
&lt;p&gt;绝逼会有人说闷骚，从上高中到现在这么说的不是一天两天了，也不是一个两个了，只是我有点细腻了吧。每个人对生活的意义以及各种扯淡的事情都有自己的答案。  &lt;/p&gt;
&lt;p&gt;《天堂电影院》中有一句台词特别特别有感触：&lt;br /&gt;
Living here day by day, you think it's the center of the world. You believe nothing will ever change. Then you leave: a year, two years. When you come back, everything's changed. The thread's broken. What you came to find isn't there. What was yours is gone. You have to go away for a long time… many years… before you can come back and find your people. The land where you were born. But now, no. It's not possible. Right now you're blinder than I am.  &lt;/p&gt;
&lt;p&gt;在这里居住了一天又一天，你认为这里就是世界的中心。你相信一切都永不会改变。然后你离开了，一年，两年，当你回来时，一切都变了。那条线断了，你所寻找的并不是这里。你只能再次离开很长时间……很多年……直到你能回来寻找你的人们，你出生的土地。但是现在不可能。现在你比我还要瞎。  &lt;/p&gt;
&lt;p&gt;为啥我扯这么远，大半夜的。其实幸福也挺简单的，有人爱着，有爱着的人。有努力的方向，对生活有热情，自然就会拥有无限的可能。多多与周围的朋友、亲人加深联系。  &lt;/p&gt;
&lt;p&gt;要对人真诚、要热爱生活，要努力工作，虽然很想拥有，但是现在还没有，这个就是生活的现实，每个人都要面对这个现实，但我相信这个世界上的另外一个角落，肯定还有另外一个人也在做同样的事情。我期望这种碰面已经发生或者正在发生或者将要发生，我会珍惜的，不想错过。  &lt;/p&gt;
&lt;p&gt;人生如戏，也许我们在别人的戏里连一个跑龙套的都算不上。但是即使我们只是一个演员，但也要演出自己，只要努力、勇敢就会有希望，在那些我们珍惜的人的生命中会变得越来越重要。  &lt;/p&gt;
&lt;p&gt;今天晚上真的好乱，应付生活中各种问题的勇气，能够说明一个人如何定义生活的意义，我们都要好好的，晚安。  &lt;/p&gt;</summary><category term="杂乱无章"></category></entry><entry><title>2015年总结</title><link href="http://lannis.github.io/articles/the-summary-of-the-year-2015/" rel="alternate"></link><updated>2015-12-31T23:47:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-12-31:articles/the-summary-of-the-year-2015/</id><summary type="html">&lt;h3&gt;2015年总结&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;转眼间&lt;/em&gt;&lt;/strong&gt;2016年了，以前从来没有说一年下来总结过，总感觉一年结束了是一件很开心很快乐的事情，人又具有这种尿性，就是在经历苦难的时候才会成长，才懂得反思。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;情感&lt;/em&gt;&lt;/strong&gt;可以说是一团糟糕，年初和EX分手弄的人精疲力尽，不管怎么样，不是不懂得珍惜和包容，而是真的不合适。我觉得吧，经历过一段算不得正常的感情，对我来说也是一种成长。夏天时又认识了一个妹子，人长的漂亮，是自己喜欢的类型，而且性格方面都很合适，关键是合得来，后来就交往了，但是人生不完美之事十之八九，发生了好多好多事情，但我希望，即使遇到再多的苦难，也会坚持下去，因为就像那英唱的那句歌词：有个爱你的人不容易，要懂得珍惜和爱护彼此。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;健身&lt;/em&gt;&lt;/strong&gt;方面，今年可以说让自己相对满意的一点，刚刚过完年后长胖了，上班爬5楼都累的气喘吁吁的，体重达到82KG。后来下定决心锻炼，而且刚好赶上了春天的那个时候。4月份开始每天坚持马甲线，坚持了差不多166天，当然锻炼只有无氧运动是不够的，因此每天另外附加3分钟平板支撑以及上班4公里跑步。到10月份时体重已经降到71KG了，目标是70KG，实在难以达到，冬天了锻炼的少了，主要是雾霾太重了，室外锻炼得不偿失。希望春节前可以到70吧。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;生活&lt;/em&gt;&lt;/strong&gt;方面，今年唯一做成的一件拖了好些年的事情，就是把驾照考下来了，每一科都是一次性通过，达到了自己的期望，就是异地报名太贵了，学车时候刚刚是夏天最热的时候，再热再苦，但是只要有目标就可以坚持。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;工作&lt;/em&gt;&lt;/strong&gt;方面，今年的工作模式还跟往年差不多，只是自己在HW经历的多了，很多事情看的开了，不会再去瞎BB了，只要把事情做好就好了。上半年工作相对认真投入点，下半年对外来说要投入的多一些，依然是每天看PostgreSQL开源社区的提交代码，已经坚持两年多了，希望可以继续坚持下去。后来GreenPlum开源了，我又投入到GP的代码学习中了，最近还在做这个事情。在HW工作怎么说相对要辛苦一些，心累一些，但是对个人的磨砺来说呵呵还是有的。&lt;/p&gt;
&lt;p&gt;Happy New Year Sweety.&lt;/p&gt;</summary><category term="年度总结"></category></entry><entry><title>Change Tracking Log in GreenPlum</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-04/" rel="alternate"></link><updated>2015-12-30T23:32:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-12-30:articles/greeplum-code-analysis-04/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;距离&lt;/em&gt;&lt;/strong&gt;上次写点东西差不多有一个月了，回过头来看一下，之前写的最后一篇其实还差那么一点，一直拖着没有补上，就是关于Change tracking log的部分。上次只是简略的提了一下，其实其中的内容还是有必要总结学习一下的。  &lt;/p&gt;
&lt;h4&gt;Why use CTL&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;在&lt;/em&gt;&lt;/strong&gt;上次的博客中主要描述的是resync机制，即segment mirror down掉后再起来，primary如何同步mirror不再位时产生的数据信息的。对比来看，PostgreSQL中，standby down掉后再起来，只需要从REDO的WAL最后向primary请求日志，primary只需要从此位置将后续的连续WAL日志发送给standby，standby redo后即可重新达到sync状态。然而在GreemPlum中，mirror是没有redo的，重要的事情说三遍mirror没有redo，没有redo，没有redo。primary&amp;amp;&amp;amp;mirror基于filerep做同步。所以当mirror down掉后，primary需要记录后续运行过程中产生的需要同步到mirror的信息，当mirror重新连接后，做primary resync过程中将这些信息发送给mirror即可达到一致，这个也是不得已而为之。  &lt;/p&gt;
&lt;h4&gt;How does it work&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Change tracking log(CTL)&lt;/em&gt;&lt;/strong&gt;在GreenPlum中，总共有以下几种：meta log、full log、compact log和transient log。除去meta log，其他几种类型的log都是一样的，只是说有一些细微的差别。当mirror down掉后，master上的fts首先会通知segment primary进入CTL mode。此时primary上会启动一个子进程叫Change tracking recovery process，这个进程主要有两个功能，是什么呢？&lt;/p&gt;
&lt;p&gt;1.FileRepPrimary_StartRecoveryInChangeTracking() -- 启动change tracking log&lt;br /&gt;
2.FileRepPrimary_RunChangeTrackingCompacting() -- 运行change tracking log  &lt;/p&gt;
&lt;p&gt;对于start recovery CTL而言，第一个是首先判断当前处于resync模式还是insync模式，这个是有区别的，在上一篇中介绍了resync模式的，可以看一下相关的code。insync模式下表明primary&amp;amp;&amp;amp;mirror已经同步了，此时旧的CTL信息已经没有用了，可以直接清理掉。如果当前是处于全量的resync，并且刚刚开始，此时由于全量的resync不需要依赖于CTL信息，因此直接退出。其他情况下说明需要标记CTL的信息的。第二个是扫描内存中的数据修改信息，为什么呢，因为呀，正常运行过程是在日志写盘时将信息记录到CTL中，当CTL recovery启动时，内存中含有未刷盘的日志，也就意味着可能存在未记录到CTL中的数据变化信息。此时CTL recovery需要做的事情就是将本地所有为未刷盘的日志刷盘，并且从checkpoint(Control file)往后扫描日志直到我们刚才刷新地点LSN位置，解析两者之间所有的WAL日志类型，从中提取感兴趣的日志类型，并且获取到对应修改的数据信息，将对应的数据页面的信息(s/d/r/b等，非页面内容本身)记录到CTL中，这个CTL中只记录数据的索引信息，也就能解释了前面文章中，inc resync模式下，对于普通的relation需要借助CTL中记录的信息读取页面发送到mirror了。  &lt;/p&gt;
&lt;p&gt;对于run CTL而言，其做的事情很简单即将full log经transient压缩为compact log，当然这里的压缩不是说压缩数据信息，而是一种数据整合，用到的思想就是同一个relation，同一个block，我们只需要记录最后被更改的那次即可。这样可以大大压缩full log中对同一个block的多次记录。这里还会引申出一个问题full log哪里来。  &lt;/p&gt;
&lt;p&gt;Full log在Change tracking mode中总共有两个来源: 第一个就是前面提到的start recovery; 另外一个是Change tracking mode下segment primary仍然是处于活跃状态的，backends仍然可以处理业务，自然会产生xlog，full log就是在这个过程中产生的，在上层处理业务过程中去做CTL的收集会非常麻烦，但是在xloginsert过程中，只需要识别出感兴趣的日志类型，并在日志插入时直接提取rdata中的的数据页面信息，存入full log。  &lt;/p&gt;
&lt;p&gt;至此Change tracking log基本上介绍完了，再回顾一下上一篇文章中提到的resync机制，resync manager负责从persistent表中获取需要做sync的表信息，如果是inc sync的话还需要参考CTL中的信息，并将这些信息插入到filerepresync哈希表中。resync worker从hash表中提取信息进行resyncwrite或者incwrite。感兴趣的可以看一下上文中列出的几个函数，对于一个需要做增量的relation而言，只会调用incwrite而不会调用resyncwrite。resyncwrite只会处理full sync，inc的PT表，以及Apend only的catchup，incwrite当然只处理inc的普通表了。  &lt;/p&gt;
&lt;p&gt;今天重新看这一部分代码时发现了很多细节上的问题，其中一个问题太明显了，而且影响比较大，就给GreenPlum社区提了一下，希望可以解决吧。  &lt;/p&gt;
&lt;p&gt;2015年还有整整一天的时间就过完了，希望2016年能够有一个好的开始，工作顺利，生活也一切顺利，忙起来也要注意休息，调整好心态，毕竟工作只是生活的一部分，cjjlp.  &lt;/p&gt;
&lt;p&gt;Good night Sweety, Good night World.&lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>最后一颗子弹--GreenPlum中Resync机制</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-03/" rel="alternate"></link><updated>2015-11-13T23:32:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-11-13:articles/greeplum-code-analysis-03/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;上周&lt;/em&gt;&lt;/strong&gt;就一直想学习一下GreenPlum中的Resync机制，但是限于工作比较忙，好几次凌晨多看着代码看到睡着了，也断断续续的。&lt;br /&gt;
双十一当天写了一个草稿，后来觉得太low了，自己都快看不明白了，也就算了，再者说双十一都去剁手了谁还弄这个呀哈哈。  &lt;/p&gt;
&lt;p&gt;这里不得不吐槽一下GreenPlum的code comments，已经github开源了，好多写的乱的很，介绍的功能与实际的实现不太相符。&lt;br /&gt;
因此一怒之下直接从一个变量开启了这次的学习之旅，可以说是一个函数isFullResync()，一趟艰难的旅行。  &lt;/p&gt;
&lt;h5&gt;Why&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;前一篇中&lt;/em&gt;&lt;/strong&gt;基本上粗略的介绍了一下GreenPlum的HA的架构(工作原理)，也就是它正常运行时是什么样的。但是本身HA就是在高可用性，在primary实例出现问题时，备胎mirror可以快速顶替，接手master下发的业务。现在考虑这样的问题，如果HA本身出问题了，其自身有是怎么修复的？  &lt;/p&gt;
&lt;h5&gt;How (in PostgreSQL)&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;在PostgreSQL中&lt;/em&gt;&lt;/strong&gt;，如果主机与备机发生断连(备机down掉)，特别是cluster下，主机需要继续work，在备机恢复后，其又是如何修复的呢？前面介绍了PostgreSQL中的replication通过的是WAL stream。备机从本地最后一个有效的WAL LSN发起请求，主机从此LSN开始往后发日志数据到备机。如果备机down掉了，备机上的日志是持久化的，当再次起来后再拿最后的LSN去向主机发起同步请求，即使主机上持续的在处理业务，只要保证备机请求的LSN点再主机上有就可以了，以为WAL是连续的，只要将此LSN之后的日志发送到备机上去做redo就可以完成主备的catchup。但是GreenPlum的主备同步机制是基于file data replication的。数据是离散的。它又是怎么做的呢？   &lt;/p&gt;
&lt;h5&gt;How (in GreenPlum)&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;在GreenPlum中&lt;/em&gt;&lt;/strong&gt;，当mirror实例down调后，master上的实例管理&lt;em&gt;ftsprobe&lt;/em&gt;进程会察觉到，然后通知master transition，进入到&lt;strong&gt;change tracking mode&lt;/strong&gt;。什么叫change tracking呢? 意思是mirror down掉，primary停止file data replication，将mirror missed的file data记录到change tracking log中(change tracking log分为几类，具体可以看一下code)。当mirror重新启动后，mirror和primary之间进入resync模式。目的是将mirror missed的数据同步过来。当主备同步完成后，系统状态将进入sync模式。  &lt;/p&gt;
&lt;p&gt;从Resync模式来看，Resync分为两种：Full Resync以及Incremental Resync，两种的Resync机制是不同的。按照正常的思维如果需要做Resync特别是Full Resync需要进行所有的数据目录下的数据遍历以及同步，实际上在GreenPlum中使用了另外一种方法：将所有persistent的relation分类存到几个persistent系统表中，当然这些系统表的记录的信息不是pg_class那种，而是与同步mirror相关的一些字段。在Resync前，也就是Transition阶段，会将需要同步的信息更新到persistent系统表中。在Resync manage时，将这些信息同persistent系统表中提出来插入到哈希表中。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;*Full Resync&lt;/em&gt;&lt;/strong&gt;*扫描persistent表中所有的relation，对于每一个普通的relation而言，并不是同步所有的数据页面，而是要满足下面的条件的：  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;            for (blkno = entry-&amp;gt;mirrorBufpoolResyncCkptBlockNum; blkno &amp;lt; numBlocks; blkno++)   
                {    
                    XLogRecPtr  endResyncLSN = (isFullResync() ?   
                                                FileRepResync_GetEndFullResyncLSN() :  
                                                FileRepResync_GetEndIncrResyncLSN());

                    if (XLByteLE(PageGetLSN(page), endResyncLSN) &amp;amp;&amp;amp;  
                        XLByteLE(entry-&amp;gt;mirrorBufpoolResyncCkptLoc, PageGetLSN(page)))   
                    {  
                        smgrwrite(smgr_relation,   
                                  blkno,  
                                  (char *)BufferGetBlock(buf),  
                                  FALSE);  
                    }
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;略微想一下就明白了，其实GreenPlum想做一种增量式的全量，只同步上次ResyncCheckpoint之后的信息，实际看一下code发现还没有做完，仍然是同步整个relation，当然对于单个relation内部，增量也是类似的(增量有些特殊的relation需要做full sync处理)。    &lt;br /&gt;
对于Append Only的relation而言，resync似乎就简单许多了，只需要同步mirror missed的数据就可以了。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Incremental Resync&lt;/em&gt;&lt;/strong&gt;相对于Full Resync而言，其并不做persistent系统表们的扫描，通过一个内部的SPI查询，获取到Change Tracking Log中记录的miss掉的relation，并且这部分miss调的relation，我们只同步endResyncLSN之后的页面。一个是之前的一个是之后的和FullCOPY要区分清楚。  &lt;/p&gt;
&lt;p&gt;从进程角度来看，Resync主要有由两类进程ResyncManager和ResyncWorker来完成。目前来看ResyncManager有且只会有一个，ResyncWorker有四个。这个和它的注释不一样，注释上说默认是一个worker，最多可以启动8个，GUC可配置...&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;ResyncManager&lt;/em&gt;&lt;/strong&gt;负责识别出来哪些relation需要做resync，将这些信息存入到到shmem哈希表中，以及预处理resync到mirror的特殊操作(ReCreate以及ReDrop)。从调用关系来看清晰明了：  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    FileRepPrimary_StartResyncManager：    
           FileRepResyncManager_InResyncTransition:  
                  ChangeTracking_RecordLastChangeTrackedLoc  
                  PersistentFileSysObj_MarkWholeMirrorFullCopy (full)  
                  PersistentFileSysObj_MarkSpecialScanIncremental (inc)  
                  PersistentFileSysObj_MarkPageIncrementalFromChangeLog (inc)  
                  PersistentFileSysObj_MarkAppendOnlyCatchup (inc)  
                  PersistentFileSysObj_MirrorReDrop  
                  PersistentFileSysObj_MirrorReCreate  
                  PersistentFileSysObj_MarkMirrorReDropped  
                  PersistentFileSysObj_MarkMirrorReCreated  
   FileRepPrimary_RunResyncManager:  
          PersistentFileSysObj_ResynchronizeScan  
          PersistentFileSysObj_ResynchronizeRefetch  
          FileRepResync_InsertEntry
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;&lt;em&gt;ResyncWorker&lt;/em&gt;&lt;/strong&gt;负责从shmem哈希表中获取需要同步到mirror的信息进行resync。  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    FileRepPrimary_RunResyncWorker:  
           FileRepPrimary_GetResyncEntry  
           FileRepPrimary_ResyncWrite  
           FileRepPrimary_ResyncBufferPoolIncrementalWrite
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;经历这一系列复杂的过程后，Primary和mirror有重新恢复了sync状态。everything is ok。  &lt;/p&gt;
&lt;h5&gt;What 点(tu)赞(cao)&lt;/h5&gt;
&lt;p&gt;GreenPlum的HA是一套复杂比较高的机制，相对于PostgreSQL而言，有赞美的一面，也有烦恼的一面。先说好的吧，GreenPlum的主备同步完全走的是memory，相当快，并且没有用WAL，意味着备机不需要做恢复，在主机down掉后，failover可以瞬间完成。但是在正常的mirror file sync以及change tracking过程中，由于需要并发控制mirror lock给主机上的业务带来了很大的负担。    &lt;/p&gt;
&lt;p&gt;PostgreSQL的HA基本上和业务是隔离的，业务进行中不需要关注主备同步，只有在commit的时候看一下其关注的WAL是否已经同步到备机了(sync模式下)，异步模式下完全没有影响，但是当主机down掉后，failover备机需要做redo来恢复，可能还会比较慢，并且采用WAL物理传输，效率多少有点不尽人意。当然萝卜白菜各有所爱，你有你的选择。  &lt;/p&gt;
&lt;p&gt;后面有机会，有时间再学习一下Greenplum PostgreSQL等等其他各种niubility的技术。&lt;br /&gt;
Good night Sweety, Good night World.  &lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>GreenPlum中高可用实现与恢复简介</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-02/" rel="alternate"></link><updated>2015-11-04T00:03:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-11-04:articles/greeplum-code-analysis-02/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;在上一篇&lt;/em&gt;&lt;/strong&gt;文章中介绍了除了master外，primary和mirror的进程以及其主要的作用。本文主要从业务流程上将各个进程的处理功能串联一下。 &lt;/p&gt;
&lt;h4&gt;GreenPlum中的文件&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;在PostgreSQL数据库&lt;/em&gt;&lt;/strong&gt;中主要存在两类文件：数据文件和非数据文件。这两个概念在GreenPlum中用BufferPoolFile和FlatFile来说明。相对于PostgreSQL，在GreenPlum增加了另外一种文件类别--append only，什么意思呢？查了一下相关的概念:  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This allows for more compact storage on disk because each row does not need to store the MVCC(Unlike traditional database systems which use locks for concurrency control, Greenplum Database (as does PostgreSQL) maintains data consistency by using a multiversion model (multiversion concurrency control or MVCC). This means that while querying a database, each transaction sees a snapshot of data which protects the transaction from viewing inconsistent data that could be caused by (other) concurrent updates on the same data rows. This provides transaction isolation for each database session.MVCC, by eschewing explicit locking methodologies of traditional database systems, minimizes lock contention in order to allow for reasonable performance in multiuser environments. The main advantage to using the MVCC model of concurrency control rather than locking is that in MVCC locks acquired for querying (reading) data do not conflict with locks acquired for writing data, and so reading never blocks writing and writing never blocks reading.) transaction visibility info. This saves 20 bytes per row. AO tables can also be compressed.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;根据前面&lt;/em&gt;&lt;/strong&gt;介绍的primary和mirror多进程差异，需要思考的一个问题是，数据如何在其之间&lt;em&gt;同步&lt;/em&gt;的？在GreenPlum中定义了一类文件同步操作接口，在primary上主要为FileRepPrimary_mirror&lt;em&gt;，在mirror上主要为FileRepMirror_&lt;/em&gt;。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;前面提到&lt;/em&gt;&lt;/strong&gt;在GreenPlum中总共有三类文件类型，拿primary为例，其在FileRepPrimary_mirror*之上封装了三类操作，分别为：&lt;br /&gt;
&lt;code&gt;cdb/cdbmirroredappendonly.c: MirroredAppendOnly_Open();MirroredAppendOnly_Create();...  
cdb/cdbmirroredbufferpool.c: MirroredBufferPool_Open();MirroredBufferPool_Create();...   
cdb/cdbmirroredflatfile.c: MirroredFlatFile_Open();MirroredFlatFile_Create();...&lt;/code&gt;&lt;br /&gt;
实际上在cdb目录下还存在另外一种mirror操作：cdbmirroredfilesysobj.c中定义的接口，实际上这些操作并没有直接参与primary-mirror同步，此处不详细展开。  &lt;/p&gt;
&lt;h4&gt;GreenPlum中的高可用&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;那么&lt;/em&gt;&lt;/strong&gt;介绍了这些接口的概念后，业务数据如何在primary和mirror间同步的呢？举一个很简单的列子：针对一个simple table，执行语句INSERT INTO table VALUES (...)往表中插入记录。语句经过词法-&amp;gt;语法-&amp;gt;语义-&amp;gt;计划-&amp;gt;优化-&amp;gt;执行，可能简单语句会跳过很多处理，最终会调用heap_insert将记录插入到heap page中，并且针对这个插入操作封装一条xlog record插入到wal page中。数据最终被转化为格式化的信息存到了两类文件中，&lt;em&gt;数据文件&lt;/em&gt;以及&lt;em&gt;日志文件&lt;/em&gt;。在GreenPlum中这两种存储的信息会从primary同步到mirror。   &lt;/p&gt;
&lt;p&gt;回忆一下，在PostgreSQL中的高可用是这样的：主机(primary)上执行insert同样会产生数据和日志信息并写入存储介质，存在一个进程walsender进程，周期性检测日志文件是否被更新，看清楚是日志文件 日志文件 日志文件，如果发现日志文件发生更新，则&lt;strong&gt;从日志文件中&lt;/strong&gt;读取新插入的那些日志记录，通过网络发送到备机(mirror)，备机alreceiver进程收到日志记录后写入到相应的日志文件中，由恢复进程startup读取文件中新写入的日志记录进行恢复，从而完成主备的一个同步过程。由于涉及到跨网络的进程传输，因此在walsender-walreceiver之间增加了心跳信息。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;GreenPlum&lt;/em&gt;&lt;/strong&gt;与PostgreSQL不同之处在于，日志和数据都会同步到备机，而不单单是日志，并且同步的方式不同，信息的同步直接是从内存同步而没有经过写盘读取磁盘上的数据这样的过程，效率相对要高一些。  &lt;/p&gt;
&lt;h5&gt;日志同步&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;产生日志时&lt;/em&gt;&lt;/strong&gt;，backend进程会调用XLogWrite函数将日志信息写入磁盘，并且根据条件决定是否需要flush。在GreenPlum中，日志的打开读写都与主备同步点滴相关。写记录来举例一下，在PostgreSQL中使用write函数将日志写入磁盘就完了，在GreenPlum中要复杂的多，具体而言，因为日志文件是flat file，因此此处使用MirroredFlatFile_Write函数替换了write函数。    &lt;/p&gt;
&lt;p&gt;MirroredFlatFile_Write函数中，首先调用前面介绍的更底层的操作接口FileRepPrimary_MirrorWrite将数据发送给备机，然后使用FileSeek&amp;amp;FileWrite接口将数据才真正的写入本地日志文件。    &lt;/p&gt;
&lt;p&gt;展开来看FileRepPrimary_MirrorWrite函数中，首先通过FileRep_ReserveShmem()从共享内存申请空间，然后针对要同步的数据，构造FileRepMessageHeader，将消息头以及需要同步的数据放入申请的共享空间。使用FileRep_IpcSignal通知消费者去共享内存中取数据。这个就是所谓前面提到的通过信号量及共享内存进行程序内多进程的同步。  &lt;/p&gt;
&lt;p&gt;这里的消费者就是primary sender进程，进程的工作方式以及作用参见前文中的介绍，sender进程将数据再封装发送到备机端， 备机的mirror receiver进程将受到的数据进行初步解析确定属于哪种类型的数据，将数据同样放入本地的接受共享空间，针对不同的数据类型使用ipc信号通知不同的消费者，这里就是为什么备机上会有三个消费者(mirror consumer、mirror consumer writer以及mirror consumer append only)的原因了。  &lt;/p&gt;
&lt;p&gt;当前场景下日志数据属于flat file，此处通知的是mirror comsumer进程，mirror comsumer进程从共享内存中取到最新的日志数据，发现类型为FileRepOperationWrite，将日志写入对应的日志文件。本次日志信息同步结束。  &lt;/p&gt;
&lt;h5&gt;数据同步&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;数据同步&lt;/em&gt;&lt;/strong&gt; 不同于日志同步，日志同步在日志记录产生时就会同步，而数据并非如此，INSERT修改或者产生页面后，页面被缓存在bufferpool中，当发生checkpoint时，会调用flushbuffer将所有脏页面刷盘，最终调用存储底层smgrwrite的实现mdwrite将数据页面写入磁盘。  &lt;/p&gt;
&lt;p&gt;在GreenPlum中数据的同步就发生在这个阶段，mdwrite真正的实现被封装为MirroredBufferPool_Write，就是我们上面提到的其中一类接口中的一种。MirroredBufferPool_Write底层调用FileRepPrimary_MirrorWrite将页面数据同步到备机，整体流程与日志类似，此处不再详述。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;实际上&lt;/em&gt;&lt;/strong&gt;在GreenPlum中的主备同步，存在同步和异步的区别，即有些操作主机不需要等待数据同步到备机，比如前面提到的两类。同样存在其他操作需要强同步的，在GreenPlum中的实现方式一般为：主机先将操作信息放入发送共享队列，同时插入到共享哈希表中，然后进行本地操作，最后等待检查哈希表中备机反馈的信息完成后，操作才算完成。  &lt;/p&gt;
&lt;h5&gt;GreenPlum中的恢复&lt;/h5&gt;
&lt;p&gt;在GreenPlum中只有产生实际数据的实例才需要恢复，和PostgreSQL不同的是，因为数据是直接被同步到备机的，所以备机不需要恢复，在主机发生故障，备机failover时其效率肯定是很不错的。  对于primary和master而言，数据库的恢复与PostgreSQL基本类似，不同之处是在reaper中如果是startup进程退出，则根据条件会拉起另外几个恢复进程进行额外的处理。&lt;/p&gt;
&lt;p&gt;morning sweety.&lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>GreenPlum进程结构简介</title><link href="http://lannis.github.io/articles/greeplum-code-analysis-01/" rel="alternate"></link><updated>2015-10-31T22:45:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-10-31:articles/greeplum-code-analysis-01/</id><summary type="html">&lt;p&gt;前一段时间&lt;a href="https://github.com/greenplum-db/gpdb"&gt;GreenPlum&lt;/a&gt;数据库正式开源了，对于整个行业来说冲击比较大。李元佳(华为/PostgresSQL)写了两篇文章分享分析为什么GreenPlum要开源，以及其开源的影响。 &lt;br /&gt;
我相信很多数据厂商在第一时间拿到了相关的已经开发的技术文档以及在github上托管的代码进行分析，作为一个数据库内核开发人员而言，可能不会直接面对其对市场的冲击带来的压力，但是学习并研究其相关的代码，能够接地气的深入了解到前沿的技术，对自己也是一个很大的提升。  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;GreenPlum&lt;/em&gt;&lt;/strong&gt;相关的开源协议以及其各种高大上的介绍，这里就不重复再重复了，网上太多了。提一点, GreenPlum是基于PostgreSQL 8.2.13内版本做的开发，当然可能最初的版本不是这个，通过一系列开源特性回合回合到这个版本。通过copyrights可以看到，从06年到现在，GreenPlum已经做了10年了，时间可以证明一切，在此表示敬意。  &lt;/p&gt;
&lt;p&gt;鉴于自己的工作性质，我可能从以下几个方面学习并分享其技术: 进程管理、高可用、备份、恢复以及存储管理等。随着自己学习的加深也可能会多少涉及到其他部分。  &lt;/p&gt;
&lt;p&gt;相对PostgreSQL而言，GreenPlum的进程管理要复杂的多，我们知道在PostgreSQL中通过针对pmState采用状态机进行自我管理。通过阅读GreenPlum的代码我们会发现，其在更high level上增加了一个叫pmModuleState的结构用以管理HA的transition/replication等，复杂度要高的多。  &lt;/p&gt;
&lt;p&gt;在GreenPlum中primary主要包含以下几个进程(ckp/bgw等暂不考虑):&lt;br /&gt;
&lt;em&gt; 1 postmaster process                      &lt;/em&gt;和PostgreSQL功能基本类似，不再详述&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 2 primary process                         &lt;em&gt;负责拉起所有primary相关的进程并负责相关的日志刷新(FileRep_Main)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 3 primary receiver ack process                &lt;/em&gt;接受listensocket0上的连接，连接建立后处理mirror发送的的ack消息,将消息插入shmem(FileRepAckPrimary_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 4 primary sender process                  &lt;em&gt;发起连接连mirror，监控fileRepShmemArray上的信息，重组业务消息发送给mirror(FileRepPrimary_RunSender)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 5 primary consumer ack process                &lt;/em&gt;处理receiver ack收到的消息, 更新到fileRepAckHashShmem-&amp;gt;hash哈希表中(FileRepAckPrimary_RunConsumer)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 6 primary recovery progress               &lt;em&gt;根绝各种消息类型，定期插入不同的hearbeat消息到哈希表，并检查最终从mirror返回更新到哈希表的状态(FileRepPrimary_RunHeartBeat)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 7 primary verification progress           &lt;/em&gt;verify进程，根据请求进行verify(FileRepPrimary_StartVerification)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 8 sweeper progress                            &lt;em&gt;没有细看，字面意思类似于PostgreSQL中的vacuum,只不过监控的是每个backend的CPU状态(BackoffSweeper)&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;mirror主要包含以下几个进程：&lt;br /&gt;
&lt;em&gt; 1 postmaster process                      &lt;/em&gt;和PostgreSQL功能基本类似，不再详述&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 2 mirror progress                         &lt;em&gt;负责拉起所有mirror相关的进程并负责相关的日志刷新(FileRep_Main)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 3 mirror receiver progress                    &lt;/em&gt;接受listenSocket0上的连接，连接建立后处理primary发送的业务消息，通过内部的状态转换决定当前处理方式环节，如先获取消息类型，reserve消息空间，接受数据，通知消费者等(FileRepMirror_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 4 mirror consumer progress                    &lt;em&gt;consumer，类型为FileRepMessageTypeXLog，处理消息中的具体文件操作信息，如打开、写数据、刷盘、关闭，truncate等(FileRepMirror_RunConsumer)&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 5 mirror consumer writer progress         &lt;/em&gt;consumer，类型为FileRepMessageTypeWriter，同上&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 6 mirror consumer append only progress        &lt;em&gt;consumer，类型为FileRepMessageTypeAO01，同上&lt;/em&gt;&lt;br /&gt;
&lt;em&gt; 8 mirror sender ack progress              &lt;/em&gt;发起连接连primary，监控fileRepAckShmemArray上的信息, 发送ack消息给primary(FileRepAckMirror_RunReceiver)&lt;em&gt;&lt;br /&gt;
&lt;/em&gt; 9 mirror verification progress                &lt;em&gt;consumer，类型为FileRepMessageTypeVerify，同上&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;限于GreeenPlum代码的复杂程度，当前理解有限。先到这里了，后面会加入业务操作，从WAL/数据角度看HA以及进程在GreenPlum中是如何运作的， 如果你对PostgreSQL了解的话，此时应该可以有点眉目了，就是GreenPlum中的primary/mirror同步不单单是WAL。&lt;br /&gt;
一般而言看这种复杂的数据库，可以从多个角度，我一般喜欢从常驻进程/线程分析，看看什么条件会收到请求，这些请求被如何处理了，这些请求的来源又是什么等等。&lt;br /&gt;
补充一点，程序内部多进程采用的是ipc和shmem同步到消息，程序间走的是基于tcp的libpq。  &lt;/p&gt;
&lt;p&gt;时间已经凌晨一点多了，晚安  &lt;/p&gt;</summary><category term="GreenPlum"></category></entry><entry><title>rewind in PostgreSQL</title><link href="http://lannis.github.io/articles/rewind/" rel="alternate"></link><updated>2015-10-30T21:30:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-10-30:articles/rewind/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;一个月&lt;/em&gt;&lt;/strong&gt;没有写文章了，这一个月确实比较忙。十一西安到北京，转至青岛，回家，返回西安。回来后又要驾照考试。  &lt;/p&gt;
&lt;p&gt;回到正文上次写到本文准备介绍一下时间线的问题，基于当前的形式，暂且放一下，今天我来介绍PostgreSQL中一个工具rewind。rewind是一个增量备份工具，最早由vmware开发，后来推送到社区后被接纳，我们得以学习到，其实在去年，基于工作性质，我们就做过类似rewind的demo，只是限于时间没有好好细化，搁置了半年之久，后来发现rewind社区已经做了，我花了半天的时间读了一下相关的代码，结构和思想还是比较清晰的。  &lt;/p&gt;
&lt;p&gt;PostgreSQL中传统的全量备份是基于文件系统的拷贝，为了保证在线备份及恢复的一致性，PostgreSQL增加了备份模式，这里不在详细介绍。后来有一个类似的外部工具出现了--rman，日本写的。rman支持全量和增量，全量为文件拷贝，增量是基于全量的基础上，通过当前全量备份的LSN与当前数据页面的LSN作比较，在数据量大时效率仍然不是很好。  &lt;/p&gt;
&lt;p&gt;与rman不同的是rewind采用了一种全新的视角来修复primary/standby关系，rewind通过解析备机上的WAL日志文件逆向获取那些需要还原的数据信息从主机上讲需要还原的信息重新同步到备机。原因是通过日志我们可以获知在备机上发生了什么，参见前文。有两个前提：  备机上从某一时刻和主机分道扬镳，这一个时刻的日志我们可以获取到，并且后续的日志都存在；fullpagewrite。第一个前提比较好理解，第二个前提具体在下文介绍。  &lt;/p&gt;
&lt;p&gt;rewind工具没有采用传统的备机视角，而是采用的普通的客户端视角，通过一系列SQL查询获取其需要的信息。主要过程有以下几部分：&lt;br /&gt;
1.必要的参数检查。&lt;br /&gt;
2.连接主机，对比主备机上control文件，确定两者同源及一些条件的检查。&lt;br /&gt;
3.根据时间线历史文件获取主备分开的日志LSN。&lt;br /&gt;
4.检查当前的备机是否可以不需要做rewind。&lt;br /&gt;
5.前向扫描日志，找到主备一致点前的checkpoint，以这个checkpoint为基准向后解析日志。&lt;br /&gt;
6.初始化filemap结构，后续用来存储需要同步的文件及页面信息。&lt;br /&gt;
7.通过SQL查询的方式获取主机上所有的文件信息，并于本地文件比较，有几种情况，主机上有备机上没有(COPY)，主机比备机大(COPYTAIL)，备机比主机大(TRUNCATE)等等。&lt;br /&gt;
8.读取备机上的文件，检查哪些文件不在主机的文件列表中，需要插入到filemap中标记为要删除(REMOVE)。&lt;br /&gt;
9.从前面找的checkpoint开始解析日志，获取日志中的bkpb中的rel block信息，讲此信息以bit map的方式插入到filemap结构中。&lt;br /&gt;
10.对最终生成的filemap做排序。&lt;br /&gt;
11.遍历filemap，分类处理每一种类型，对于需要向主机同步的，采用SQL的方式，创建临时表，将所有需要向主机同步的文件/块信息以记录的方式放到表中。执行特定的语句，主机遍历临时表中的记录，读取相应的文件/块，发送到备机。&lt;br /&gt;
12.创建backuplabel文件以及调整control文件。&lt;br /&gt;
13.手动以备机方式拉起。  &lt;/p&gt;
&lt;p&gt;整体而言rewind的思想很不错，数据量大时不需要去遍历所有的数据文件，但是限制也颇多，比如，需要完全保留日志，对主备机的停止模式有严格的要求，必须打开fullpagewrite，等等。尽管如此，仍然不失为一个高效率的主备修复工具。当然在很多方面可以做优化，使得工具的适用范围更加广。&lt;/p&gt;</summary><category term="rewind"></category><category term="rman"></category><category term="PostgreSQL"></category></entry><entry><title>timeline in PostgreSQL</title><link href="http://lannis.github.io/articles/learning/" rel="alternate"></link><updated>2015-09-17T22:20:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-17:articles/learning/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;PostgreSQL&lt;/em&gt;&lt;/strong&gt;数据库是一个开源的传统关系性数据库，目前在国内的应用是越来越广泛的。为什么？有些觉得这个数据库功能比较强大，社区比较活跃，然后使用PostgreSQL为基线可以开发针对自己需求场景的数据库，而不必去承担一些责任。  &lt;/p&gt;
&lt;p&gt;但是在我看来，这些都是一些外在的，真正好的还是数据库本身。从2013年起，每次的commit记录我都会看一下学习一下，当然啦，很多patch是看不懂，个人水平有限... PostgreSQL社区的committer真的是一群大牛们，他们对于技术的热爱以及对于CODE本身的严谨程度让我感到震撼，Tom Lane(社区的大哥大，从199×年开始就在运营社区)对每一次提交都有很详细的记录以及很清晰的comments，甚至因为几个white blank或者因为几个注释的单词拼写错误就会去提交一次，让人从内心深处敬佩。所以学习他们的code，就像在欣赏一件艺术品。有他们这些人，PostgreSQL的前景是美好的。  &lt;/p&gt;
&lt;p&gt;因工作需要从2012年下半年就开始接触PostgreSQL相关的事情，印象比较深刻的是关于时间线(timeline)的概念，当时真的是完全不理解，也许吧看过科幻电影、小说。这个是一个很有意思的话题，一个人回到过去杀掉了自己的祖母，然后这个人会发生什么悖论。  &lt;/p&gt;
&lt;p&gt;在数据库中时间线是一个看得见摸得着的东西，因为基于可靠性，数据库会记录日志，一般的日志都是时间+内容的方式，就像日记一样，某一天发生了什么事情。这样一天一天的累积，我们可能写了好多本日记，有这个月的，有去年的，有前年的...   &lt;/p&gt;
&lt;p&gt;举个例子，现在拿起手中的日记本，比如2012年的日记，翻开某一页，其中日记上这么写着，今天想去北京玩，结果因为某些事情没有去成，导致现在没有认识某些人或者没有做某些事。然后我可能会想如果当时下定决心会怎么样... 也会有一个不一样的人生吧。扯远了，数据库中时间线的存在就像一连串起来的日记，我可以选择一天回到过去，做出另外一种选择，描绘另外一种人生。比如之前的时间线是1，那么回到过去做出一些不一样选择后的时间线叫2，以此类推。  &lt;/p&gt;
&lt;p&gt;在PostgreSQL中日志是以WAL记录的方式存储，每一个WAL日志段文件像是一个日记本，我们写完一个，会买另外一个继续写。同样的道理，日志段文件中记录的record就是我们那一天一天的日记。数据库的恢复机制，允许我们从一个过去的时间点开始恢复，恢复到一定时间后后面的日志可以选择性不恢复，从而以全新的状态运行。  &lt;/p&gt;
&lt;p&gt;今天就到这里了，下次主要想总结的是PostgreSQL中replication跨时间线传输在当前版本中的限制。  &lt;/p&gt;
&lt;p&gt;马上中秋节了，中秋节要去北京一趟，去见一些想见的人，然后在北京上三天班，接着去青岛，然后回家。祝中秋快乐。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;MISS U&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</summary><category term="timeline"></category><category term="PostgreSQL"></category></entry><entry><title>70周年</title><link href="http://lannis.github.io/articles/%E6%83%B3%E4%BD%A0/" rel="alternate"></link><updated>2015-09-04T00:32:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-04:articles/想你/</id><summary type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;九月三号&lt;/em&gt;&lt;/strong&gt;阅兵，昨天上午从开始看到结束&lt;br /&gt;
好些年没有这么认真了的看阅兵了，好像感觉也好久没有阅兵了哈哈&lt;/p&gt;
&lt;p&gt;西安下午下着雨,好像明天也会下雨...&lt;br /&gt;
&lt;img alt="想你" src="http://img4.duitang.com/uploads/item/201205/17/20120517133805_FZPsv.jpeg" /&gt;&lt;/p&gt;</summary><category term="抗战"></category><category term="评论"></category></entry><entry><title>About Me</title><link href="http://lannis.github.io/articles/About%20Me/" rel="alternate"></link><updated>2015-09-01T07:49:00+08:00</updated><author><name>Lannis</name></author><id>tag:lannis.github.io,2015-09-01:articles/About Me/</id><summary type="html">&lt;p&gt;Hello Pelican, Markdown and Github Blogs.&lt;/p&gt;
&lt;h4&gt;感想&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;今天&lt;/em&gt;&lt;/strong&gt;是第一次成功配置github blog，很开心，因为刚开始不是特别的顺利。&lt;br /&gt;
甚至安装Ubuntu Kylin后一段时间Windows 10都启动不起来了。万幸通过boot repair修复了。&lt;br /&gt;
后续相关的学习及心得会在此blog上更新，欢迎访问和评论，哈哈哈&lt;/p&gt;
&lt;h4&gt;链接&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;下面&lt;/em&gt;&lt;/strong&gt;是配置的几个学习的链接，以供收藏和学习:&lt;br /&gt;
&lt;a href="http://www.jianshu.com/p/1e402922ee32/"&gt;Markdown--入门指南&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://www.linuxzen.com/shi-yong-pelicanda-zao-jing-tai-bo-ke.html"&gt;使用Pelican打造静态博客&lt;/a&gt;&lt;br /&gt;
&lt;a href="http://heylinux.com/archives/3337.html?utm_source=tuicool"&gt;使用Pelican + Markdown + GitHub Pages来撰写Blog&lt;/a&gt;&lt;/p&gt;</summary><category term="Pelican"></category><category term="Markdown"></category></entry></feed>